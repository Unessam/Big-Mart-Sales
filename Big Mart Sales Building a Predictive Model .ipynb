{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Building\n",
    "to Build a model, I'll try different algorithms and evaluate their performances by RMSE, Finally I'll apply a stacking method which combines all the algorithms to see if I get a better result\n",
    "from sklearn.model_selection import train_test_split\n",
    "​\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "​\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "​\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "​\n",
    "from matplotlib import pyplot\n",
    ".iloc\n",
    "X=train.iloc[:,:-1]\n",
    "y=train.iloc[:,-1:]\n",
    "# first I define a stacking function\n",
    "# first I define a stacking function\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LinearRegression()))\n",
    "    level0.append(('knn', KNeighborsRegressor()))\n",
    "    level0.append(('cart', DecisionTreeRegressor()))\n",
    "    level0.append(('svm', SVR()))\n",
    "    level0.append(('ada', AdaBoostRegressor()))\n",
    "    level0.append(('xgb', XGBRegressor()))\n",
    "    level0.append(('rf', RandomForestRegressor()))\n",
    "    level0.append(('la', Lasso()))\n",
    "    level0.append(('rd', Ridge()))\n",
    "    # define meta learner model\n",
    "    level1 = LinearRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "# next I define a function to evaluate different models\n",
    "# next I define a function to evaluate different models\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    neg_scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    scores= np.sqrt(abs(neg_scores))\n",
    "    return scores\n",
    "function to create a dictionary of desired algorithms\n",
    "# here I define function to create a dictionary of desired algorithms\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LinearRegression()\n",
    "    models['knn'] = KNeighborsRegressor()\n",
    "    models['cart'] = DecisionTreeRegressor()\n",
    "    models['svm'] = SVR()\n",
    "    models['ada'] = AdaBoostRegressor()\n",
    "    models['xgb']= XGBRegressor()\n",
    "    models['rf']= RandomForestRegressor()\n",
    "    models['la']= Lasso()\n",
    "    models['rd']= Ridge()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    "# creating a dictionary of models\n",
    "models = get_models()\n",
    "​\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()\n",
    "It's obvious that stacking improved the preformance of the model, also linear regression and ridge algorithms perform quite good.\n",
    "the performance by stacking model might even progress if we tune parameters for each algorithm beforehand.\n",
    "Now it's time to predict sales for our test data and upload our submission to the contest.\n",
    "_\n",
    "model=get_stacking()\n",
    "model.fit(X, y)\n",
    "y_pred=model.predict(test)\n",
    "submission=pd.read_csv('sample_submission')\n",
    "Importnant Note:\n",
    "after submitting my prediction to the solution checker for the first time, I got a notice telling submission file includes some negative values, which is quite non-sense since I am predicting sales figures.\n",
    "I googled the problem and found out that the application of Linear regression and Ridge might cause to get negative values in my prediction. why? since the algorithms are based on y=ax+b, which extrapolate predictions, that means it is possible that the interception for the equation to be negative, that means some values somewhere, some how would be predicted negative.\n",
    "How to solve this issue? well, there are two approaches, one way is to use another algorithm, and the other is to apply log transformation to independent variable (target value). I tried the second approch and then inversed both transformation (normalization, log transformation) for predicted values.\n",
    "y_pred_inv\n",
    "y_pred_inv=norm_scaler_3.inverse_transform(y_pred.reshape(-1,1))\n",
    "y_pred_inv_exp=np.exp(y_pred_inv)\n",
    "submission.head()\n",
    "Item_Identifier\tOutlet_Identifier\tItem_Outlet_Sales\n",
    "0\tFDW58\tOUT049\t7.125195\n",
    "1\tFDW14\tOUT017\t7.312422\n",
    "2\tNCN55\tOUT010\t6.419935\n",
    "3\tFDQ58\tOUT017\t7.789930\n",
    "4\tFDY38\tOUT027\t8.545310\n",
    "_inv_exp\n",
    "submission=submission.drop(['Item_Outlet_Sales'], axis=1)\n",
    "submission['Item_Outlet_Sales']=y_pred_inv_exp\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "after submitting the submission file I've got the score of 1232.9415921557, which is not bad for a model without any hyperparameter tuning, however, it is possible to improve the performance of this model by tuning it's parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
